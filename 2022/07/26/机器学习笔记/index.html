<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>机器学习笔记 | DancingLoki's Dream</title><meta name="keywords" content="ML"><meta name="author" content="DancingLoki"><meta name="copyright" content="DancingLoki"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="序言这次准备跟着斯坦福CS229进行机器学习的学习，想着之前有看过吴恩达老师的课程讲解，但是没有动过手，因此了解还是比较模糊，希望这次能够多动手来理解，然后我朋友还推荐了224n和224w，打算等着这个基础看完再去学习。另我学长推荐了林轩田，但我看推导公式的时候有些迷糊，打算也许之后再看看？ 本篇是我自己的学习记录，如果对你有所帮助就是我最大的快乐，那么话不多说，一起进入学习吧！ 注意由于要在博客">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记">
<meta property="og:url" content="http://example.com/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="DancingLoki&#39;s Dream">
<meta property="og:description" content="序言这次准备跟着斯坦福CS229进行机器学习的学习，想着之前有看过吴恩达老师的课程讲解，但是没有动过手，因此了解还是比较模糊，希望这次能够多动手来理解，然后我朋友还推荐了224n和224w，打算等着这个基础看完再去学习。另我学长推荐了林轩田，但我看推导公式的时候有些迷糊，打算也许之后再看看？ 本篇是我自己的学习记录，如果对你有所帮助就是我最大的快乐，那么话不多说，一起进入学习吧！ 注意由于要在博客">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/MLStudy.jpg">
<meta property="article:published_time" content="2022-07-26T08:10:46.000Z">
<meta property="article:modified_time" content="2022-07-28T05:39:38.429Z">
<meta property="article:author" content="DancingLoki">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/MLStudy.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://example.com/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-07-28 13:39:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><link rel="stylesheet" href="APlayer.min.css"><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js" async></script><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/./img/MLStudy.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">DancingLoki's Dream</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-07-26T08:10:46.000Z" title="发表于 2022-07-26 16:10:46">2022-07-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-07-28T05:39:38.429Z" title="更新于 2022-07-28 13:39:38">2022-07-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>这次准备跟着斯坦福CS229进行机器学习的学习，想着之前有看过吴恩达老师的课程讲解，但是没有动过手，因此了解还是比较模糊，希望这次能够<strong>多动手</strong>来理解，然后我朋友还推荐了224n和224w，打算等着这个基础看完再去学习。另我学长推荐了林轩田，但我看推导公式的时候有些迷糊，打算也许之后再看看？</p>
<p>本篇是我自己的学习记录，如果对你有所帮助就是我最大的快乐，那么话不多说，一起进入学习吧！</p>
<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><p>由于要在博客里显示图片，对md文件里面的图片进行了路径的修改，即，现在的路径为：</p>
<p><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20220728123720131.png" alt="image-20220728123720131"></p>
<p>原因就是hexo的读取图片的路径和typora不一致，我们需要在<strong>typora文字编辑界面</strong>中把图片路径从 <code>同名文件夹\imagename</code> 修改为 <code>imagename</code> 。可以直接使用typora 的<strong>Ctrl+F</strong> 进行全局替换，将路径前缀替换为空即可。若想获取原路径只需添上去掉的路径名即可</p>
<h1 id="CS229"><a href="#CS229" class="headerlink" title="CS229"></a>CS229</h1><h2 id="线性回归（linear-regression）"><a href="#线性回归（linear-regression）" class="headerlink" title="线性回归（linear regression）"></a>线性回归（linear regression）</h2><p>线性回归也许是最简单的学习算法之一。</p>
<p>咱们先来聊几个使用监督学习来解决问题的实例。假如咱们有一个数据集，里面的数据是俄勒冈州波特兰市的<br>$$<br>47<br>$$<br> 套房屋的面积和价格：</p>
<table>
<thead>
<tr>
<th align="center">居住面积（平方英尺）</th>
<th align="center">价格（千美元）</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$2104$</td>
<td align="center">$400$</td>
</tr>
<tr>
<td align="center">$1600$</td>
<td align="center">$330$</td>
</tr>
<tr>
<td align="center">$2400$</td>
<td align="center">$369$</td>
</tr>
<tr>
<td align="center">$1416$</td>
<td align="center">$232$</td>
</tr>
<tr>
<td align="center">$3000$</td>
<td align="center">$540$</td>
</tr>
<tr>
<td align="center">$\vdots$</td>
<td align="center">$\vdots$</td>
</tr>
</tbody></table>
<p>用这些数据来投个图：</p>
<p><img src="https://raw.githubusercontent.com/Kivy-CN/Stanford-CS-229-CN/master/img/cs229note1f1.png"></p>
<p>有了这样的数据，我们怎样才能学会预测波特兰其他房屋的价格，以及它们的居住面积？</p>
<p>这里要先规范一下符号和含义，这些符号以后还要用到，咱们假设<br>$$<br>x^{(i)}<br>$$<br> 表示 “输入的” 变量值（在这个例子中就是房屋面积），也可以叫做<strong>输入特征</strong>；然后咱们用<br>$$<br>y^{(i)}<br>$$<br> 来表示“输出值”，或者称之为<strong>目标变量</strong>，这个例子里面就是房屋价格。这样的一对<br>$$<br>(x^{(i)},y^{(i)})<br>$$<br>就称为一组训练样本，然后咱们用来让机器来学习的数据集，就是——一个长度为<br>$$<br>m<br>$$<br> 的训练样本的列表<br>$$<br>{(x^{(i)},y^{(i)}); i &#x3D; 1,\dots ,m}<br>$$<br>——也叫做一个<strong>训练集</strong>。另外一定注意，这里的上标$(i)$只是作为训练集的索引记号，和数学乘方没有任何关系，千万别误解了。另外我们还会用大写的<br>$$<br>X<br>$$<br>来表示 <strong>输入值的空间</strong>，大写的<br>$$<br>Y<br>$$<br>表示<strong>输出值的空间</strong>。在本节的这个例子中，输入输出的空间都是实数域，所以<br>$$<br>X &#x3D; Y &#x3D; R<br>$$<br>然后再用更加规范的方式来描述一下监督学习问题，我们的目标是，给定一个训练集，来让机器学习一个函数<br>$$<br>h: X → Y<br>$$<br>，让<br>$$<br>h(x)<br>$$<br> 是一个与对应的真实<br>$$<br>y<br>$$<br> 值比较接近的评估值。由于一些历史上的原因，这个函数<br>$$<br>h<br>$$<br> 就被叫做<strong>假设（hypothesis）</strong>。用一个图来表示的话，这个过程大概就是下面这样：<img src="/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20220728073728343.png" alt="image-20220728073728343"></p>
<p>如果我们要预测的目标变量是连续的，比如在咱们这个房屋价格-面积的案例中，这种学习问题就被称为<strong>回归问题。</strong> 如果<br>$$<br>y<br>$$<br>只能取一小部分的离散的值（比如给定房屋面积，咱们要来确定这个房子是一个住宅还是公寓），这样的问题就叫做<strong>分类问题。</strong></p>
<p><strong>现在回到问题：</strong></p>
<p>为了让我们的房屋案例更有意思，咱们稍微对数据集进行一下补充，增加上每一个房屋的卧室数目：</p>
<table>
<thead>
<tr>
<th align="center">居住面积（平方英尺）</th>
<th align="center">卧室数目</th>
<th align="center">价格（千美元）</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$2104$</td>
<td align="center">$3$</td>
<td align="center">$400$</td>
</tr>
<tr>
<td align="center">$1600$</td>
<td align="center">$3$</td>
<td align="center">$330$</td>
</tr>
<tr>
<td align="center">$2400$</td>
<td align="center">$3$</td>
<td align="center">$369$</td>
</tr>
<tr>
<td align="center">$1416$</td>
<td align="center">$2$</td>
<td align="center">$232$</td>
</tr>
<tr>
<td align="center">$3000$</td>
<td align="center">$4$</td>
<td align="center">$540$</td>
</tr>
<tr>
<td align="center">$\vdots$</td>
<td align="center">$\vdots$</td>
<td align="center">$\vdots$</td>
</tr>
</tbody></table>
<p>现在，输入特征<br>$$<br>x<br>$$<br> 就是在<br>$$<br>R^2<br>$$<br> 范围取值的一个二维向量了。例如<br>$$<br>x_1^{(i)}<br>$$<br> 就是训练集中第<br>$$<br>i<br>$$<br>个房屋的面积，而<br>$$<br>x_2^{(i)}<br>$$<br> 就是训练集中第<br>$$<br>i<br>$$<br>个房屋的卧室数目。（通常来说，设计一个学习算法的时候，选择哪些输入特征都取决于你,你完全可以选择包含其他的特征，例如房屋是否有壁炉，卫生间的数量啊等等。关于特征筛选的内容会在后面的章节进行更详细的介绍，不过目前来说就暂时先用给定的这两个特征了。）</p>
<p>要进行这个监督学习，咱们必须得确定好如何在计算机里面对这个<strong>函数&#x2F;假设</strong><br>$$<br>h<br>$$<br> 进行表示。咱们现在刚刚开始，就来个简单点的，咱们把 $y$ 假设为一个以<br>$$<br>x<br>$$<br> 为变量的线性函数：</p>
<p>$$<br>h_\theta  (x) &#x3D; \theta_0 + \theta_1 \times x_1 + \theta_2 \times x_2<br>$$</p>
<p>这里的<br>$$<br>\theta_i<br>$$<br>是<strong>参数</strong>（也可以叫做<strong>权重</strong>），是从<br>$$<br>x<br>$$<br> 到<br>$$<br>y<br>$$<br> 的线性函数映射的空间参数。在不至于引起混淆的情况下，咱们可以把<br>$$<br>h_\theta(x)<br>$$<br> 里面的<br>$$<br>\theta<br>$$<br>  省略掉，就简写成<br>$$<br>h(x)<br>$$<br>。另外为了简化公式，咱们还设<br>$$<br>x_0 &#x3D; 1<br>$$<br>（这个为 <strong>截距项 intercept term</strong>）。这样简化之后就有了：</p>
<p>$$<br>h(x) &#x3D; \sum^n_{i&#x3D;0}  \theta_i x_i &#x3D; \theta^T x<br>$$</p>
<p>等式最右边的<br>$$<br>\theta<br>$$<br>和<br>$$<br>x<br>$$<br> 都是向量，等式中的<br>$$<br>n<br>$$<br> 是输入变量的个数（不包括<br>$$<br>x_0<br>$$<br>）。</p>
<p>现在，给定了一个训练集，咱们怎么来挑选&#x2F;学习参数<br>$$<br>\theta<br>$$<br> 呢？一个看上去比较合理的方法就是让<br>$$<br>h(x)<br>$$<br> 尽量逼近<br>$$<br>y<br>$$<br>，至少对咱已有的训练样本能适用。用公式的方式来表示的话，就要定义一个函数，来衡量对于每个不同的<br>$$<br>\theta<br>$$<br> 值，<br>$$<br>h(x^{(i)})<br>$$<br> 与对应的<br>$$<br>y^{(i)}<br>$$<br> 的距离。这样用如下的方式定义了一个 <strong>成本函数 （cost function</strong>）:</p>
<p>$$<br>J(\theta) &#x3D; \frac 12 \sum^m_{i&#x3D;1}(h_\theta(x^{(i)})-y^{(i)})^2<br>$$</p>
<h3 id="1-梯度下降—-最小均方算法（LMS-algorithm）"><a href="#1-梯度下降—-最小均方算法（LMS-algorithm）" class="headerlink" title="1. 梯度下降—-最小均方算法（LMS algorithm）"></a>1. 梯度下降—-最小均方算法（LMS algorithm）</h3><p>我们希望选择一个能让<br>$$<br>J(\theta)<br>$$<br> 最小的<br>$$<br>\theta<br>$$<br> 值。怎么做呢，咱们先用一个搜索的算法，从某一个对<br>$$<br>\theta<br>$$<br> 的“初始猜测值”，然后对<br>$$<br>\theta<br>$$<br> 值不断进行调整，来让<br>$$<br>J(\theta)<br>$$<br> 逐渐变小，最好是直到我们能够达到一个使<br>$$<br>J(\theta)<br>$$<br> 最小的<br>$$<br>\theta<br>$$<br>。具体来说，咱们可以考虑使用梯度下降法（gradient descent algorithm），这个方法就是从某一个<br>$$<br>\theta<br>$$<br>的初始值开始，然后逐渐重复更新：<br>$$<br>\theta_j :&#x3D; \theta_j - \alpha \frac \partial {\partial\theta_j}J(\theta)<br>$$</p>
<p>（上面的这个更新要同时对应从<br>$$<br>0<br>$$<br> 到<br>$$<br>n<br>$$<br> 的所有<br>$$<br>j<br>$$<br> 值进行。）这里的<br>$$<br>\alpha<br>$$<br> 也称为学习速率。这个算法是很自然的，逐步重复朝向<br>$$<br>J<br>$$<br> 降低最快的方向移动。</p>
<p> 本文中 <strong>:&#x3D;</strong>  表示的是计算机程序中的一种赋值操作，是把等号右边的计算结果赋值给左边的变量，a :&#x3D; b$就表示用 b 的值覆盖原有的a值。</p>
<p>如果写的是 a &#x3D;&#x3D; b 则表示的是判断二者相等的关系。</p>
<p>要实现这个算法，咱们需要解决等号右边的导数项。首先来解决只有一组训练样本<br>$$<br>(x, y)<br>$$<br> 的情况，这样就可以忽略掉等号右边对<br>$$<br>J<br>$$<br> 的求和项目了。公式就简化下面这样：</p>
<p>$$<br>\begin{aligned}<br>\frac \partial {\partial\theta_j}J(\theta) &amp; &#x3D; \frac \partial {\partial\theta_j} \frac  12(h_\theta(x)-y)^2\<br>&amp; &#x3D; 2 \cdot\frac 12(h_\theta(x)-y)\cdot \frac \partial {\partial\theta_j}  (h_\theta(x)-y) \<br>&amp; &#x3D; (h_\theta(x)-y)\cdot \frac \partial {\partial\theta_j}(\sum^n_{i&#x3D;0} \theta_ix_i-y) \<br>&amp; &#x3D; (h_\theta(x)-y) x_j<br>\end{aligned}<br>$$</p>
<p>当只有一个训练样本的时候，我们推导出了 LMS 规则。当一个训练集有超过一个训练样本的时候，有两种对这个规则的修改方法。第一种就是下面这个算法：<br>$$<br>\begin{aligned}<br>&amp;\qquad 重复直到收敛 { \<br>&amp;\qquad\qquad\theta_j :&#x3D; \theta_j + \alpha \sum^m_{i&#x3D;1}(y^{(i)}-h_\theta (x^{(i)}))x_j^{(i)}\quad(对每个j) \<br>&amp;\qquad}<br>\end{aligned}<br>$$<br>读者很容易能证明，在上面这个更新规则中求和项的值就是<br>$$<br>\frac {\partial J(\theta)}{\partial \theta_j}<br>$$<br> （这是因为对<br>$$<br>J<br>$$<br>的原始定义）。所以这个更新规则实际上就是对原始的成本函数<br>$$<br>J<br>$$<br>进行简单的梯度下降。这一方法在每一个步长内检查所有整个训练集中的所有样本，也叫做<strong>批量梯度下降法（batch gradient descent</strong>）。这里要注意，因为梯度下降法容易被局部最小值影响，而我们要解决的这个<strong>线性回归的优化问题只能有一个全局的而不是局部的最优解</strong>；因此，梯度下降法应该总是收敛到全局最小值（假设学习速率<br>$$<br>\alpha<br>$$<br> 不设置的过大）。<br>$$<br>J<br>$$<br> 很明确是一个凸二次函数。下面是一个样例，其中对一个二次函数使用了梯度下降法来找到最小值。</p>
<p><img src="https://raw.githubusercontent.com/Kivy-CN/Stanford-CS-229-CN/master/img/cs229note1f3.png"></p>
<p>上图的椭圆就是一个二次函数的轮廓图。图中还有梯度下降法生成的规矩，初始点位置在<br>$$<br>(48,30)<br>$$<br>。图中的画的<br>$$<br>x<br>$$<br> （用直线连接起来了）标记了梯度下降法所经过的<br>$$<br>\theta<br>$$<br> 的可用值。</p>
<p>对咱们之前的房屋数据集进行批量梯度下降来拟合<br>$$<br>\theta<br>$$<br> ，把房屋价格当作房屋面积的函数来进行预测，我们得到的结果是<br>$$<br>\theta_0 &#x3D; 71.27, \theta_1 &#x3D; 0.1345<br>$$<br>。如果把<br>$$<br>h_{\theta}(x)<br>$$<br>作为一个定义域在<br>$$<br>x<br>$$<br> 上的函数来投影，同时也投上训练集中的已有数据点，会得到下面这幅图：</p>
<p><img src="https://raw.githubusercontent.com/Kivy-CN/Stanford-CS-229-CN/master/img/cs229note1f4.png"></p>
<p>如果在数据集中添加上卧室数目作为输入特征，那么得到的结果就是<br>$$<br>\theta_0 &#x3D; 89.60, \theta_1 &#x3D; 0.1392, \theta_2 &#x3D; −8.738<br>$$<br>这个结果就是用批量梯度下降法来获得的。此外还有另外一种方法能够替代批量梯度下降法，这种方法效果也不错。如下所示<br>$$<br>\begin{aligned}<br>&amp;\qquad循环：{ \<br>&amp;\qquad\qquad i从1到m,{   \<br>&amp;\qquad\qquad\qquad\theta_j :&#x3D; \theta_j  +\alpha(y^{(i)}-h_{\theta}(x^{(i)}))x_j^{(i)} \qquad(对每个 j) \<br>&amp;\qquad\qquad}  \<br>&amp;\qquad}<br>\end{aligned}<br>$$<br>在这个算法里，我们对整个训练集进行了循环遍历，每次遇到一个训练样本，根据每个单一训练样本的误差梯度来对参数进行更新。这个算法叫做<strong>随机梯度下降法（stochastic gradient descent）</strong>，或者叫<strong>增量梯度下降法（incremental gradient descent）</strong>。批量梯度下降法要在运行第一步之前先对整个训练集进行扫描遍历，当训练集的规模<br>$$<br>m<br>$$<br> 变得很大的时候，引起的性能开销就很不划算了；随机梯度下降法就没有这个问题，而是可以立即开始，对查询到的每个样本都进行运算。通常情况下，随机梯度下降法查找到足够接近最低值的<br>$$<br>\theta<br>$$<br> 的速度要比批量梯度下降法更快一些。（也要注意，也有可能会一直无法收敛（converge）到最小值，这时候<br>$$<br>\theta<br>$$<br> 会一直在<br>$$<br>J(\theta)<br>$$<br> 最小值附近震荡；不过通常情况下在最小值附近的这些值大多数其实也足够逼近了，足以满足咱们的精度要求，所以也可以用。由于这些原因，特别是在训练集很大的情况下，随机梯度下降往往比批量梯度下降更受青睐。</p>
<p>当然更常见的情况通常是我们事先对数据集已经有了描述，并且有了一个确定的学习速率<br>$$<br>\alpha<br>$$<br>，然后来运行随机梯度下降，同时逐渐让学习速率<br>$$<br>\alpha<br>$$<br> 随着算法的运行而逐渐趋于<br>$$<br>0<br>$$<br>，这样也能保证我们最后得到的参数会收敛到最小值，而不是在最小值范围进行震荡。</p>
<p>译者注：由于以上种种原因，通常更推荐使用的都是随机梯度下降法，而不是批量梯度下降法，尤其是在训练用的数据集规模大的时候。）</p>
<h3 id="2-法方程（The-normal-equations）"><a href="#2-法方程（The-normal-equations）" class="headerlink" title="2. 法方程（The normal equations）"></a>2. 法方程（The normal equations）</h3><p>这种方法寻找起来简单明了，而且不需要使用迭代算法。这种方法就是，我们直接利用找对应导数为 0 位置的<br>$$<br>\theta_j<br>$$<br>，这样就能找到<br>$$<br>J<br>$$<br> 的最小值了。我们想实现这个目的，还不想写一大堆代数公式或者好几页的矩阵积分，所以就要介绍一些做矩阵积分的记号。</p>
<h4 id="2-1-矩阵导数"><a href="#2-1-矩阵导数" class="headerlink" title="2.1 矩阵导数"></a>2.1 矩阵导数</h4><p>假如有一个函数<br>$$<br>f: R^{m\times n} → R<br>$$<br> 从<br>$$<br>m\times n<br>$$<br> 大小的矩阵映射到实数域，那么就可以定义当矩阵为 $A$ 的时候有导函数<br>$$<br>f<br>$$<br>如下所示：</p>
<p>$$<br>\nabla_A f(A)&#x3D;\begin{bmatrix} \frac {\partial f}{\partial A_{11}} &amp; \dots  &amp; \frac {\partial f}{\partial A_{1n}} \ \vdots  &amp; \ddots &amp; \vdots  \ \frac {\partial f}{\partial A_{m1}} &amp; \dots  &amp; \frac {\partial f}{\partial A_{mn}} \ \end{bmatrix}<br>$$</p>
<p>因此，这个梯度<br>$$<br>\nabla_A f(A)<br>$$<br>本身也是一个<br>$$<br>m\times n<br>$$<br> 的矩阵，其中的第<br>$$<br>(i,j)<br>$$<br> 个元素是<br>$$<br>\frac {\partial f}{\partial A_{ij}}<br>$$<br> 。<br>假如<br>$$<br> A &#x3D;\begin{bmatrix} A_{11} &amp; A_{12} \ A_{21} &amp; A_{22} \ \end{bmatrix}<br>$$<br> 是一个<br>$$<br>2\times 2<br>$$<br>  矩阵，然后给定的函数<br>$$<br>f:R^{2\times 2} → R<br>$$<br> 为:<br>$$<br>f(A) &#x3D; \frac 32A_{11}+5A^2_{12}+A_{21}A_{22}<br>$$</p>
<p>这里面的<br>$$<br>A_{ij}<br>$$<br>表示的意思是矩阵<br>$$<br>A<br>$$<br> 的第<br>$$<br>(i,j)<br>$$<br> 个元素。然后就有了梯度：</p>
<p>$$<br>\nabla <em>A f(A) &#x3D;\begin{bmatrix} \frac  32 &amp; 10A</em>{12} \ A_{22} &amp; A_{21} \ \end{bmatrix}<br>$$</p>
<p>然后咱们还要引入<br>$$<br>trace<br>$$<br> 求迹运算，简写为<br>$$<br>tr<br>$$<br>。对于一个给定的 n x n 方形矩阵 A，它的迹定义为对角项和：</p>
<p>$$<br>trA &#x3D; \sum^n_{i&#x3D;1} A_{ii}<br>$$</p>
<p>假如 a 是一个实数，实际上 a 就可以看做是一个 1 x 1 的矩阵，那么就有 a 的迹 tr a &#x3D; a。(如果你之前没有见到过这个“运算记号”，就可以把 A 的迹看成是 tr(A)，或者理解成为一个对矩阵 A$进行操作的 trace 函数。不过通常情况都是写成不带括号的形式更多一些。) </p>
<p>如果有两个矩阵 A 和B，能够满足 AB为方阵，trace 求迹运算就有一个特殊的性质： trAB &#x3D; trBA (自己想办法证明)。在此基础上进行推论，就能得到类似下面这样的等式关系：</p>
<p>$$<br>trABC&#x3D;trCAB&#x3D;trBCA \<br>trABCD&#x3D;trDABC&#x3D;trCDAB&#x3D;trBCDA<br>$$</p>
<p>下面这些和求迹运算相关的等量关系也很容易证明。其中 A 和 B 都是方形矩阵，a 是一个实数：</p>
<p>$$<br>trA&#x3D;trA^T \<br>tr(A+B)&#x3D;trA+trB \<br>tr a A&#x3D;a trA<br>$$</p>
<p>接下来咱们就来在不进行证明的情况下提出一些矩阵导数（其中的一些直到本节末尾才用得上）。另外要注意等式(4)中的A必须是<strong>非奇异方阵（non-singular square matrices</strong>），而 |A| 表示的是矩阵 A的行列式。那么我们就有下面这些等量关系：</p>
<p>$$<br>\begin{aligned}<br>   \nabla_A tr AB &amp; &#x3D; B^T &amp; \text{(1)}\<br>   \nabla_{A^T} f(A) &amp; &#x3D; (\nabla_{A} f(A))^T &amp;\text{(2)}\<br>   \nabla_A tr ABA^TC&amp; &#x3D; CAB+C^TAB^T &amp;\text{(3)}\<br>   \nabla_A|A| &amp; &#x3D; |A|(A^{-1})^T &amp;\text{(4)}\<br>\end{aligned}<br>$$</p>
<h4 id="2-2-最小二乘法回顾（Least-squares-revisited）"><a href="#2-2-最小二乘法回顾（Least-squares-revisited）" class="headerlink" title="2.2 最小二乘法回顾（Least squares revisited）"></a>2.2 最小二乘法回顾（Least squares revisited）</h4><p>接下来咱们就继续用逼近模型（closed-form）来找到能让<br>$$<br>J(\theta)<br>$$<br> 最小的<br>$$<br>\theta<br>$$<br> 值。首先咱们把<br>$$<br>J<br>$$<br>用矩阵-向量的记号来重新表述。</p>
<p>给定一个训练集，把<strong>设计矩阵（design matrix）</strong><br>$$<br>x<br>$$<br> 设置为一个<br>$$<br>m\times n<br>$$<br> 矩阵（实际上，如果考虑到截距项，也就是<br>$$<br>\theta_0<br>$$<br> 那一项，就应该是<br>$$<br>m\times (n+1)<br>$$<br> 矩阵），这个矩阵里面包含了训练样本的输入值作为每一行：</p>
<p>$$<br>X &#x3D;\begin{bmatrix}<br>-(x^{(1)}) ^T-\<br>-(x^{(2)}) ^T-\<br>\vdots \<br>-(x^{(m)}) ^T-\<br>\end{bmatrix}<br>$$</p>
<p>然后，咱们设<br>$$<br>\vec{y}<br>$$<br> 是一个<br>$$<br>m<br>$$<br> 维向量（m-dimensional vector），其中包含了训练集中的所有目标值：</p>
<p>$$<br>y &#x3D;\begin{bmatrix}<br>y^{(1)}\<br>y^{(2)}\<br>\vdots \<br>y^{(m)}\<br>\end{bmatrix}<br>$$</p>
<p>因为<br>$$<br>h_\theta (x^{(i)}) &#x3D; (x^{(i)})^T\theta<br>$$<br>，所以可以证明存在下面这种等量关系：</p>
<p>$$<br>\begin{aligned}<br>X\theta - \vec{y}  &amp;&#x3D;<br>\begin{bmatrix}<br>(x^{(1)})^T\theta \<br>\vdots \<br>(x^{(m)})^T\theta\<br>\end{bmatrix} -<br>\begin{bmatrix}<br>y^{(1)}\<br>\vdots \<br>y^{(m)}\<br>\end{bmatrix}\<br>&amp; &#x3D;<br>\begin{bmatrix}<br>h_\theta (x^{1}) -y^{(1)}\<br>\vdots \<br>h_\theta (x^{m})-y^{(m)}\<br>\end{bmatrix}\<br>\end{aligned}<br>$$</p>
<p>对于向量<br>$$<br>\vec{z}<br>$$<br> ，则有<br>$$<br>z^T z &#x3D; \sum_i z_i^2<br>$$<br> ，因此利用这个性质，可以推出:</p>
<p>$$<br>\begin{aligned}<br>\frac 12(X\theta - \vec{y})^T (X\theta - \vec{y}) &amp;&#x3D;\frac 12 \sum^m_{i&#x3D;1}(h_\theta (x^{(i)})-y^{(i)})^2\<br>&amp;&#x3D; J(\theta)<br>\end{aligned}<br>$$</p>
<p>最后，要让<br>$$<br>J<br>$$<br> 的值最小，就要找到函数对于<br>$$<br>\theta<br>$$<br>导数。结合等式(2)和等式(3)，就能得到下面这个等式(5)：</p>
<p>$$<br>\nabla_{A^T} trABA^TC &#x3D;B^TA^TC^T+BA^TC \qquad \text{(5)}<br>$$</p>
<p>因此就有：</p>
<p>$$<br>\begin{aligned}<br>\nabla_\theta J(\theta) &amp;&#x3D; \nabla_\theta \frac 12 (X\theta - \vec{y})^T (X\theta - \vec{y}) \<br>&amp;&#x3D; \frac  12 \nabla_\theta (\theta ^TX^TX\theta -\theta^T X^T \vec{y} - \vec{y} ^TX\theta +\vec{y}^T \vec{y})\<br>&amp;&#x3D; \frac  12 \nabla_\theta tr(\theta ^TX^TX\theta -\theta^T X^T \vec{y} - \vec{y} ^TX\theta +\vec{y}^T \vec{y})\<br>&amp;&#x3D; \frac  12 \nabla_\theta (tr \theta ^TX^TX\theta - 2tr\vec{y} ^T X\theta)\<br>&amp;&#x3D; \frac  12 (X^TX\theta+X^TX\theta-2X^T\vec{y}) \<br>&amp;&#x3D; X^TX\theta-X^T\vec{y}\<br>\end{aligned}<br>$$</p>
<p>在第三步，我们用到了一个定理，也就是一个实数的迹就是这个实数本身；第四步用到了<br>$$<br>trA &#x3D; trA^T<br>$$<br> 这个定理；第五步用到了等式(5)，其中<br>$$<br>A^T &#x3D;\theta, B&#x3D;B^T &#x3D;X^TX, C&#x3D;I<br>$$<br>,还用到了等式 (1)。要让 J取得最小值，就设导数为 0 ，然后就得到了下面的<strong>法线方程（normal equations）：</strong></p>
<p>$$<br>X^TX\theta &#x3D;X^T\vec{y}<br>$$</p>
<p>所以让<br>$$<br>J(\theta)<br>$$<br> 取值最小的<br>$$<br>\theta<br>$$<br> 就是</p>
<p>$$<br>\theta &#x3D; (X^TX)^{-1}X^T\vec{y}<br>$$</p>
<p>p3 </p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">DancingLoki</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">http://example.com/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">DancingLoki's Dream</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ML/">ML</a></div><div class="post_share"><div class="social-share" data-image="/./img/MLStudy.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/07/23/%E9%87%8D%E5%90%AF%E5%8D%9A%E5%AE%A2/"><img class="next-cover" src="/./img/111.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">重启博客</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/07/23/重启博客/" title="重启博客"><img class="cover" src="/./img/111.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-23</div><div class="title">重启博客</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">DancingLoki</div><div class="author-info__description">诗酒趁年华</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/DancingLoki"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/DancingLoki" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:duzhuoshao@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://user.qzone.qq.com/1004435052/" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">我想过送你怎么样的故事，但最后还是决定送你一束金色的花，因为我没办法送你太阳，这也是我能找到最温暖最漂亮的东西</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BA%8F%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">序言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F"><span class="toc-number">2.</span> <span class="toc-text">注意</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CS229"><span class="toc-number">3.</span> <span class="toc-text">CS229</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88linear-regression%EF%BC%89"><span class="toc-number">3.1.</span> <span class="toc-text">线性回归（linear regression）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E2%80%94-%E6%9C%80%E5%B0%8F%E5%9D%87%E6%96%B9%E7%AE%97%E6%B3%95%EF%BC%88LMS-algorithm%EF%BC%89"><span class="toc-number">3.1.1.</span> <span class="toc-text">1. 梯度下降—-最小均方算法（LMS algorithm）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B3%95%E6%96%B9%E7%A8%8B%EF%BC%88The-normal-equations%EF%BC%89"><span class="toc-number">3.1.2.</span> <span class="toc-text">2. 法方程（The normal equations）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E7%9F%A9%E9%98%B5%E5%AF%BC%E6%95%B0"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">2.1 矩阵导数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E5%9B%9E%E9%A1%BE%EF%BC%88Least-squares-revisited%EF%BC%89"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">2.2 最小二乘法回顾（Least squares revisited）</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="机器学习笔记"><img src="/./img/MLStudy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习笔记"/></a><div class="content"><a class="title" href="/2022/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="机器学习笔记">机器学习笔记</a><time datetime="2022-07-26T08:10:46.000Z" title="发表于 2022-07-26 16:10:46">2022-07-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/23/%E9%87%8D%E5%90%AF%E5%8D%9A%E5%AE%A2/" title="重启博客"><img src="/./img/111.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="重启博客"/></a><div class="content"><a class="title" href="/2022/07/23/%E9%87%8D%E5%90%AF%E5%8D%9A%E5%AE%A2/" title="重启博客">重启博客</a><time datetime="2022-07-23T13:00:37.000Z" title="发表于 2022-07-23 21:00:37">2022-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/23/hello-world/" title="Hello World"><img src="/./img/111.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2022/07/23/hello-world/" title="Hello World">Hello World</a><time datetime="2022-07-23T12:49:42.165Z" title="发表于 2022-07-23 20:49:42">2022-07-23</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/./img/MLStudy.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By DancingLoki</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="7558610829" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true" data-lrcType="-1"> </div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})


document.addEventListener('pjax:send', function () {
  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>